{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T10:03:06.191216Z",
     "start_time": "2022-01-28T10:03:06.180052Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T03:15:44.639524Z",
     "start_time": "2022-01-28T03:15:44.628679Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T09:59:06.377332Z",
     "start_time": "2022-01-28T09:59:06.355811Z"
    }
   },
   "outputs": [],
   "source": [
    "class TxtProcessor() : \n",
    "    def __init__(self, lemma_dict_path = 'lemma_dict.pickle') : \n",
    "        self._lemma_dict = pd.read_pickle(lemma_dict_path)\n",
    "        self.tokenizer = get_tokenizer('basic_english')\n",
    "        self._nsp_label = {'IsNext':1, 'NotNext':0}\n",
    "        \n",
    "    def _wi_map(self, word) : \n",
    "        return self._lemma_dict.get(word, self._lemma_dict['<unk>'])\n",
    "    \n",
    "    def sent_tokenize(self, txt) : \n",
    "        tokens = self.tokenizer(txt)\n",
    "        return tokens\n",
    "    \n",
    "    def word_indexing(self, word) : \n",
    "        return self._wi_map(word)\n",
    "    \n",
    "    def preprocess(self, txt) : \n",
    "        tokens = self.sent_tokenize(txt)\n",
    "        wi_arr = np.vectorize(self._wi_map)(tokens)\n",
    "        return wi_arr\n",
    "    \n",
    "    @property\n",
    "    def lemma_dict(self) : \n",
    "        return self._lemma_dict\n",
    "    \n",
    "    @property\n",
    "    def mask_id(self) : \n",
    "        return self._lemma_dict['<mask>']\n",
    "    \n",
    "    @property\n",
    "    def unk_id(self) : \n",
    "        return self._lemma_dict['<unk>']\n",
    "\n",
    "    @property\n",
    "    def pad_id(self) : \n",
    "        return self._lemma_dict['<pad>']\n",
    "\n",
    "    @property\n",
    "    def sep_id(self) : \n",
    "        return self._lemma_dict['<sep>']\n",
    "    \n",
    "    @property\n",
    "    def cls_id(self) : \n",
    "        return self._lemma_dict['<cls>']\n",
    "    \n",
    "    @property\n",
    "    def nsp_label(self) : \n",
    "        return self._nsp_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T10:01:43.839090Z",
     "start_time": "2022-01-28T10:01:43.509004Z"
    }
   },
   "outputs": [],
   "source": [
    "class BertIterator(Dataset) : \n",
    "    def __init__(self,\n",
    "                filename = 'prep_docs.txt',\n",
    "                lemma_dict_path = 'lemma_dict.pickle',\n",
    "                 seq_len=256,\n",
    "                in_memory=True) : \n",
    "        \n",
    "        if in_memory is False : \n",
    "            NotImplementedError(\"Only in-memory version is supported\")\n",
    "            \n",
    "        self.docs = self._load_txt_in_memory(filename)\n",
    "        self.prep = TxtProcessor(lemma_dict_path)\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def __len__(self) : \n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, item) : \n",
    "        txt1, txt2 = self._sample_txt_from_line(item)\n",
    "        \n",
    "        wi1, mask_l1 = self._generate_mask(txt1)\n",
    "        wi2, mask_l2 = self._generate_mask(txt2)        \n",
    "        wi2, mask_lv2, nsp_l = self._generate_nsp(wi2, mask_l2)\n",
    "        \n",
    "        wi = self._concat_sequences(wi1, wi2)\n",
    "        mask_l = self._concat_sequences(mask_l1, mask_l2)\n",
    "        \n",
    "        return {\n",
    "            'text' : wi,\n",
    "            'mlm' : mask_l,\n",
    "            'nsp' : nsp_l\n",
    "        }\n",
    "\n",
    "    def _load_txt_in_memory(self, fname) : \n",
    "        docs = open(fname).read().splitlines()\n",
    "        self.length = len(docs) # take end-line\n",
    "        return docs\n",
    "    \n",
    "    def _sample_txt_from_line(self, idx, get_pair=True) :\n",
    "        txt1, txt2 = self.docs[idx].split(\"\\t\")\n",
    "        if get_pair :\n",
    "            return txt1, txt2\n",
    "        else : \n",
    "            return txt2        \n",
    "    \n",
    "    def _generate_mask(self, txt) : \n",
    "        wi = self.prep.preprocess(txt1)\n",
    "        \n",
    "        # random-sampling mask targeted index\n",
    "        index_arr = np.arange(len(wi))\n",
    "        np.random.shuffle(index_arr)\n",
    "        index_arr = index_arr[:int(index_arr.shape[0]*0.15)]\n",
    "        mask_label[index_arr] = wi[index_arr]\n",
    "        \n",
    "        # seperate mask targeted index into 3 conditions\n",
    "        mask_idx_arr = index_arr[:int(len(index_arr)*0.8)]\n",
    "        replace_idx_arr = index_arr[int(len(index_arr)*0.8):int(len(index_arr)*0.9)]\n",
    "        unchanged_idx_arr = index_arr[int(len(index_arr)*0.9):]\n",
    "        \n",
    "        # apply masking\n",
    "        wi[mask_idx_arr] = self.prep.mask_id\n",
    "        random_alloc_wi = np.random.choice(np.arange(4, len(prep.lemma_dict)),\n",
    "                                           size=replace_idx_arr.shape[0], replace=False)\n",
    "        wi[replace_idx_arr] = random_alloc_wi\n",
    "        \n",
    "        return wi, mask_label\n",
    "\n",
    "    def _generate_nsp(self, wi, label) : \n",
    "        p = random.random()\n",
    "        if p > 0.5 : # NotNext\n",
    "            \n",
    "            rand_sample_idx = np.random.randint(low=5, high=self.length, size=1).item()\n",
    "            txt = self._sample_txt_from_line(idx=rand_sample_idx, get_pair=False)\n",
    "            wi, label = self._generate_mask(txt)\n",
    "            return wi, label, self.prep.nsp_label['NotNext']\n",
    "            \n",
    "        return wi, label, self.prep.nsp_label['IsNext']\n",
    "    \n",
    "    def _concat_sequences(self, wi1, wi2) : \n",
    "        pad_length = self.seq_len - 3 - wi1.shape[0] - wi2.shape[0]\n",
    "        cated = [self.prep.cls_id] + wi1.tolist() + [self.prep.sep_id] + wi2.tolist() + [self.prep.sep_id]\n",
    "        cated = cated[:self.seq_len] # list type\n",
    "        padded = torch.tensor(cated + [self.prep.pad_id] * pad_length).long().contiguous()\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T10:01:53.442287Z",
     "start_time": "2022-01-28T10:01:43.843977Z"
    }
   },
   "outputs": [],
   "source": [
    "iterator = BertIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader(iterator, batch_size=128, shuffle=False, num_workers=10,\n",
    "           pin_memory=False, drop_last=False, timeout=0,\n",
    "           worker_init_fn=None, *, prefetch_factor=2,\n",
    "           persistent_workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T10:01:53.497093Z",
     "start_time": "2022-01-28T10:01:53.447338Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in iterator : \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
