{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:53:56.326682Z",
     "start_time": "2022-02-01T13:53:54.957008Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from dataset import iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:53:56.339464Z",
     "start_time": "2022-02-01T13:53:56.330914Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:53:56.348268Z",
     "start_time": "2022-02-01T13:53:56.341796Z"
    }
   },
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module) : \n",
    "    def __init__(self, vocab_size, seq_length, d_model) : \n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.tok_emb = nn.Embedding(vocab_size, d_model, padding_idx=train_dataset.prep.pad_id)\n",
    "        self.pos_emb = nn.Embedding(seq_length, d_model)\n",
    "        self.seg_emb = nn.Embedding(3, d_model, padding_idx=train_dataset.prep.pad_id)\n",
    "        \n",
    "    def generate_enc_mask_m(self, src) :       \n",
    "        mask_m = (src != train_dataset.prep.pad_id).unsqueeze(1).unsqueeze(2)\n",
    "        return mask_m\n",
    "    \n",
    "    def forward(self, txt, seg) : \n",
    "        emb = self.tok_emb(txt)\n",
    "        pos = torch.arange(0, emb.shape[1]).unsqueeze(0).repeat(emb.shape[0], 1).to(emb.device)\n",
    "        summed = emb + self.pos_emb(pos) + self.seg_emb(seg)\n",
    "        return summed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled Dot-Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:53:56.355052Z",
     "start_time": "2022-02-01T13:53:56.349974Z"
    }
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module) : \n",
    "    def __init__(self, d_model) : \n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, q, k, v, mask) :         \n",
    "        score = torch.matmul(q, k.permute(0,1,3,2).contiguous())/math.sqrt(d_model)\n",
    "        score = score.masked_fill(mask==0, -1e10)\n",
    "        scaled_score = torch.softmax(score, dim=-1)\n",
    "        \n",
    "        attention = torch.matmul(scaled_score, v).permute(0,2,3,1).contiguous()\n",
    "        attention = attention.view(attention.shape[0], attention.shape[1], self.d_model)\n",
    "        \n",
    "        return self.fc(attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:53:56.362265Z",
     "start_time": "2022-02-01T13:53:56.356542Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module) : \n",
    "    def __init__(self, d_model, seq_length, n_head) : \n",
    "        super().__init__()\n",
    "        assert d_model % n_head == 0, f\"n_head({n_head}) does not divide d_model({d_model})\"\n",
    "\n",
    "        self.n_div_head = d_model//n_head\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_length\n",
    "        self.n_head = n_head\n",
    "\n",
    "        self.Q = nn.Linear(d_model,  d_model)\n",
    "        self.K = nn.Linear(d_model,  d_model)\n",
    "        self.V = nn.Linear(d_model,  d_model)\n",
    "        \n",
    "    def div_and_sort_for_multiheads(self, projected, seq_len) : \n",
    "        div = projected.view(projected.shape[0], self.n_head, seq_len, self.n_div_head)\n",
    "        return div\n",
    "    \n",
    "    def forward(self, emb) :\n",
    "        q = self.div_and_sort_for_multiheads(self.Q(emb), self.seq_len)    \n",
    "        k = self.div_and_sort_for_multiheads(self.K(emb), self.seq_len)\n",
    "        v = self.div_and_sort_for_multiheads(self.V(emb), self.seq_len)\n",
    "\n",
    "        return q,k,v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-process the sub-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:53:56.367284Z",
     "start_time": "2022-02-01T13:53:56.363790Z"
    }
   },
   "outputs": [],
   "source": [
    "class PostProcessing(nn.Module) : \n",
    "    def __init__(self, d_model, p=0.1) : \n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        \n",
    "    def forward(self, emb, attn) : \n",
    "        return self.ln(emb+self.dropout(attn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Position-wise FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:53:56.372273Z",
     "start_time": "2022-02-01T13:53:56.368691Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionwiseFFN(nn.Module) : \n",
    "    def __init__(self, d_model, d_ff) : \n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "    def forward(self, x) : \n",
    "        return self.fc2(self.act(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:53:56.379517Z",
     "start_time": "2022-02-01T13:53:56.374475Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module) : \n",
    "    def __init__(self, vocab_size, seq_length, d_model, d_ff, n_head, dropout_p) : \n",
    "        super().__init__()\n",
    "        \n",
    "        self.ma = MultiHeadAttention(d_model, seq_length, n_head).to(device)\n",
    "        self.sdp = ScaledDotProductAttention(d_model)\n",
    "        \n",
    "        self.pp1 = PostProcessing(d_model, dropout_p)\n",
    "        self.pp2 = PostProcessing(d_model, dropout_p)\n",
    "        \n",
    "        self.positionwise_ffn = PositionwiseFFN(d_model, d_ff)\n",
    "            \n",
    "    def forward(self, emb, mask_m) :\n",
    "\n",
    "        q,k,v = self.ma(emb)    \n",
    "        attn = self.sdp(q,k,v, mask=mask_m)\n",
    "        \n",
    "        attn = self.pp1(emb, attn)\n",
    "        z = self.positionwise_ffn(attn)\n",
    "\n",
    "        return self.pp2(attn, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:53:56.386823Z",
     "start_time": "2022-02-01T13:53:56.381012Z"
    }
   },
   "outputs": [],
   "source": [
    "class BERT(nn.Module) : \n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 seq_length,\n",
    "                 d_model,\n",
    "                 d_ff,\n",
    "                 n_head,\n",
    "                 dropout_p,\n",
    "                 n_enc_layer) : \n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embber = InputEmbedding(vocab_size, seq_length, d_model)\n",
    "        \n",
    "        enc = EncoderLayer(vocab_size, seq_length, d_model, d_ff, n_head, dropout_p)\n",
    "        \n",
    "        self.enc = nn.ModuleList([deepcopy(enc) for _ in range(n_enc_layer)])\n",
    "        \n",
    "        self.mlm_fc = nn.Linear(d_model, vocab_size)\n",
    "        self.nsp_fc = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, txt, seg) : \n",
    "        \n",
    "        emb = self.embber(txt, seg)\n",
    "        mask_m = self.embber.generate_enc_mask_m(txt)\n",
    "\n",
    "        for enc_layer in self.enc : \n",
    "            emb = enc_layer(emb, mask_m)\n",
    "\n",
    "        return torch.log_softmax(self.mlm_fc(emb), dim=2), torch.sigmoid(self.nsp_fc(emb[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:54:03.722947Z",
     "start_time": "2022-02-01T13:53:56.388203Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "seq_len = 128\n",
    "\n",
    "train_dataset = iterator.BertIterator(filename = '../data/prep_train.txt',\n",
    "                                tokenizer_model_path = '../data/m.model',\n",
    "                                seq_len=seq_len)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = iterator.BertIterator(filename = '../data/prep_valid.txt',\n",
    "                                tokenizer_model_path = '../data/m.model',\n",
    "                                seq_len=seq_len)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:54:04.003391Z",
     "start_time": "2022-02-01T13:54:03.727731Z"
    }
   },
   "outputs": [],
   "source": [
    "d_model = 64\n",
    "d_ff = d_model * 4\n",
    "n_head = 8\n",
    "vocab_size = train_dataset.prep.vocab_size\n",
    "dropout_p = 0.1\n",
    "n_enc_layer = 3\n",
    "seq_length = train_dataset.seq_len\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T14:19:17.076990Z",
     "start_time": "2022-02-01T14:19:16.983566Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.DataParallel(BERT(vocab_size,\n",
    "             seq_length,\n",
    "             d_model,\n",
    "             d_ff,\n",
    "             n_head,\n",
    "             dropout_p,\n",
    "             n_enc_layer)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Label weight\n",
    "- mlm's label has huge imbalance within it, sampling the labels and prepare the weight arr for its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:56:55.920735Z",
     "start_time": "2022-02-01T13:54:08.978157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd6d3fd54064d5fbbd62cebca829efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlm_label_container = []\n",
    "cnt = 0\n",
    "\n",
    "for data in tqdm(train_dataloader, total=len(train_dataloader)) : \n",
    "    mlm = data['mlm'][data['mlm'] != 0]\n",
    "    mlm_label_container.append(mlm)\n",
    "    cnt += 1\n",
    "    if cnt == 2000 : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:56:56.138329Z",
     "start_time": "2022-02-01T13:56:55.924776Z"
    }
   },
   "outputs": [],
   "source": [
    "count_arr = torch.unique(torch.cat(mlm_label_container), return_counts=True)\n",
    "weight = -torch.log(count_arr[1] / count_arr[1].sum())\n",
    "weight_arr = torch.full((vocab_size,), fill_value=weight.median().item()).type(torch.FloatTensor)\n",
    "weight_arr[count_arr[0]] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T14:18:44.760567Z",
     "start_time": "2022-02-01T14:18:44.752884Z"
    }
   },
   "outputs": [],
   "source": [
    "top_freq_wi = count_arr[0].numpy()[np.argsort(count_arr[1].numpy())[-20:]]\n",
    "top_freq_words = train_dataset.prep.sp.id_to_piece(top_freq_wi.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T13:56:56.296382Z",
     "start_time": "2022-02-01T13:56:56.140824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"label weight distribution\")\n",
    "plt.plot(torch.sort(weight_arr).values.data.numpy())\n",
    "# plt.xlim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T14:19:19.200881Z",
     "start_time": "2022-02-01T14:19:19.187207Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.autograd.set_detect_anomaly(True) # -- for debugging the train progress --\n",
    "N_EPOCHS = 20\n",
    "\n",
    "criterion1 = nn.NLLLoss(ignore_index=train_dataset.prep.pad_id, weight=weight_arr).to(device)\n",
    "criterion2 = nn.BCELoss().to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, pct_start=0.01, \n",
    "                                          steps_per_epoch=len(train_dataloader), epochs=N_EPOCHS, \n",
    "                                          total_steps=N_EPOCHS * len(train_dataloader), anneal_strategy='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T14:19:22.468458Z",
     "start_time": "2022-02-01T14:19:22.427941Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, scheduler):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_total_loss = 0\n",
    "    epoch_mlm_loss = 0\n",
    "    epoch_nsp_loss = 0 \n",
    "    \n",
    "    epoch_mlm_acc = 0    \n",
    "    epoch_nsp_acc = 0    \n",
    "    cnt = 0\n",
    "    \n",
    "    for data in tqdm(dataloader, desc='train') :\n",
    "        \n",
    "        drop_data_bool = (data['seg'] == 1).sum(1) / data['seg'].shape[1] < 0.6\n",
    "        data = {k:v[drop_data_bool].to(device) for k,v in data.items()}\n",
    "        \n",
    "        optimizer.zero_grad()        \n",
    "        mlm_pred, nsp_pred = model(data['text'], data['seg'])\n",
    "        \n",
    "        mlm_filter = torch.tensor(~np.in1d(data['mlm'].cpu().view(-1).numpy(), top_freq_wi))\n",
    "        mlm_loss = criterion1(mlm_pred.view(-1, mlm_pred.shape[-1])[mlm_filter], \n",
    "                              data['mlm'].view(-1)[mlm_filter])\n",
    "        \n",
    "        nsp_loss = criterion2(nsp_pred.squeeze(), data['nsp'].float().cuda())\n",
    "        loss = mlm_loss + nsp_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()        \n",
    "        \n",
    "        acc = (mlm_pred.view(-1,vocab_size)[mlm_filter].argmax(1) == data['mlm'].view(-1)[mlm_filter]).sum().item() / mlm_filter.sum()\n",
    "        epoch_mlm_acc += acc\n",
    "        \n",
    "        acc = (nsp_pred.argmax(1) == data['nsp']).sum() / data['nsp'].shape[0]\n",
    "        epoch_nsp_acc += acc\n",
    "        \n",
    "        epoch_total_loss += loss.item()\n",
    "        epoch_mlm_loss += mlm_loss.item()\n",
    "        epoch_nsp_loss += nsp_loss.item()        \n",
    "        cnt += 1\n",
    "        \n",
    "        if cnt % (len(dataloader)//1000) == 0 : \n",
    "            print(f'\\tTrain Total Loss: {epoch_total_loss / cnt:.3f} | Train MLM Loss: {epoch_mlm_loss / cnt:.3f} | Train NSP Loss: {epoch_nsp_loss / cnt:.3f}\\\n",
    "            | MLM ACC : {epoch_mlm_acc / cnt: .3f} | NSP ACC : {epoch_nsp_acc / cnt: .3f} | Learning Rate : {scheduler.get_last_lr()[0]:.3f}')\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "    return epoch_total_loss / cnt, epoch_mlm_loss / cnt, epoch_nsp_loss / cnt\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_total_loss = 0\n",
    "    epoch_mlm_loss = 0\n",
    "    epoch_nsp_loss = 0\n",
    "    cnt = 0\n",
    "    \n",
    "    with torch.no_grad() : \n",
    "        for data in tqdm(data, desc='valid') :\n",
    "            \n",
    "            emb, mlm_pred, nsp_pred = model(data['text'].to(device), data['seg'].to(device))\n",
    "        \n",
    "            mlm_loss = criterion(mlm_pred.transpose(1,2), data['mlm'].cuda())\n",
    "            nsp_loss = criterion(nsp_pred, data['nsp'].cuda()) \n",
    "            loss = mlm_loss + nsp_loss\n",
    "\n",
    "            epoch_total_loss += loss.item()\n",
    "            epoch_mlm_loss += mlm_loss.item()\n",
    "            epoch_nsp_loss += nsp_loss.item()        \n",
    "            cnt += 1\n",
    "    \n",
    "        if cnt % (len(dataloader)//100) == 0 : \n",
    "            print(f'\\tTrain Total Loss: {epoch_total_loss / cnt:.3f} | Train MLM Loss: {epoch_mlm_loss / cnt:.3f} | Train NSP Loss: {epoch_nsp_loss / cnt:.3f}')\n",
    "            \n",
    "    return epoch_total_loss / cnt, epoch_mlm_loss / cnt, epoch_nsp_loss / cnt\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T14:19:50.850106Z",
     "start_time": "2022-02-01T14:19:23.292409Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7629a71c97b44baa9f6aa4e954e7892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/26566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Total Loss: 9.121 | Train MLM Loss: 8.383 | Train NSP Loss: 0.737            | MLM ACC :  0.001 | NSP ACC :  0.520 | Learning Rate : 0.004\n",
      "\tTrain Total Loss: 8.932 | Train MLM Loss: 8.212 | Train NSP Loss: 0.719            | MLM ACC :  0.001 | NSP ACC :  0.505 | Learning Rate : 0.005\n",
      "\tTrain Total Loss: 8.850 | Train MLM Loss: 8.137 | Train NSP Loss: 0.712            | MLM ACC :  0.001 | NSP ACC :  0.505 | Learning Rate : 0.005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-5cf4d56428f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mlm_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_nsp_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mvalid_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_mlm_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_nsp_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-716c8ced16d8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdrop_data_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hfcp/anaconda3/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hfcp/anaconda3/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hfcp/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hfcp/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hfcp/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hfcp/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RESEARCH/pytorch-transformers-implementation/bert/dataset/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtxt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_txt_from_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mwi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mwi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mwi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_lv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsp_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_nsp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_l2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RESEARCH/pytorch-transformers-implementation/bert/dataset/iterator.py\u001b[0m in \u001b[0;36m_generate_mask\u001b[0;34m(self, txt)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# random-sampling mask targeted index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mindex_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mindex_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_total_loss, train_mlm_loss, train_nsp_loss = train(model, train_dataloader, optimizer, scheduler)\n",
    "    valid_total_loss, valid_mlm_loss, valid_nsp_loss = evaluate(model, valid_dataloader, criterion)\n",
    "\n",
    "    end_time = time.time()    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_total_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_total_loss\n",
    "        torch.save(model.state_dict(), 'bert.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    \n",
    "    print(f'\\tTrain Total Loss: {train_total_loss:.3f} | Train MLM Loss: {train_mlm_loss:.3f} | Train NSP Loss: {train_nsp_loss:.3f}')    \n",
    "    print(f'\\tValid Total Loss: {valid_total_loss:.3f} | Valid MLM Loss: {valid_mlm_loss:.3f} | Valid NSP Loss: {valid_nsp_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T14:19:54.015826Z",
     "start_time": "2022-02-01T14:19:53.438147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c92ca5efbb4a848b284296f33af094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/26566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for data in tqdm(train_dataloader, desc='train') :\n",
    "    data = {k:v.to(device) for k,v in data.items()}\n",
    "    mlm_pred, nsp_pred = model(data['text'], data['seg'])\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
