{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T15:42:19.275146Z",
     "start_time": "2022-03-06T15:42:19.270339Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T15:42:21.332083Z",
     "start_time": "2022-03-06T15:42:19.279526Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from deit.dataset import iterator\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from deit.layer.classifier import DeiT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**how to prepare the teacher model?**\n",
    "- I fine-tuned the pretrained resnet18 supported from torchvision.models using our own imagenet data\n",
    "- please refer the \"train benchmark for imagenet (resnet18).ipynb\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T15:42:26.109015Z",
     "start_time": "2022-03-06T15:42:21.334910Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "teacher_model = models.resnet18(True)\n",
    "teacher_model.fc = nn.Linear(512, 115).cuda()\n",
    "teacher_model = nn.DataParallel(teacher_model)\n",
    "teacher_model.load_state_dict(torch.load(\"resnet18_imagenet_pretrained.pt\"))\n",
    "teacher_model = teacher_model.module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T15:42:26.656160Z",
     "start_time": "2022-03-06T15:42:26.114243Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iterator = iterator.DistilationImageNetIterator(is_train=True,teacher=teacher_model, device='cpu')\n",
    "valid_iterator = iterator.DistilationImageNetIterator(is_train=False,teacher=teacher_model, device='cpu')\n",
    "\n",
    "train_loader = DataLoader(train_iterator, batch_size=32*2, shuffle=True, num_workers=30)\n",
    "valid_loader = DataLoader(valid_iterator, batch_size=32*2, shuffle=False, num_workers=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T15:42:26.687616Z",
     "start_time": "2022-03-06T15:42:26.679263Z"
    }
   },
   "outputs": [],
   "source": [
    "height = 224\n",
    "width = 224\n",
    "channel = 3\n",
    "patch = 16\n",
    "d_model = 256\n",
    "d_ff = d_model * 4\n",
    "ffn_typ = 'glu'\n",
    "act_typ = 'GELU'\n",
    "n_head = 8\n",
    "dropout_p = 0.1\n",
    "n_enc_layer = 3\n",
    "output_dim = len(train_iterator.label_dict)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T15:42:26.765144Z",
     "start_time": "2022-03-06T15:42:26.691262Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.DataParallel(DeiT(\n",
    "    height,\n",
    "    width,\n",
    "    channel,\n",
    "    patch,\n",
    "    d_model,\n",
    "    d_ff,\n",
    "    ffn_typ,\n",
    "    act_typ,\n",
    "    n_head,\n",
    "    dropout_p,\n",
    "    n_enc_layer,\n",
    "    output_dim,)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T15:42:26.772878Z",
     "start_time": "2022-03-06T15:42:26.767933Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T15:42:26.796217Z",
     "start_time": "2022-03-06T15:42:26.776164Z"
    }
   },
   "outputs": [],
   "source": [
    "def train() : \n",
    "    model.train()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    for dict_ in tqdm(train_loader, desc='train') : \n",
    "        pred = model(dict_['input'].to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(pred, dict_['label'].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = (torch.argmax(pred, dim=1) == dict_['label'].to(device)).sum()\n",
    "        acc = correct.item() / dict_['label'].shape[0]\n",
    "\n",
    "        accuracies.append(acc)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    agg_acc = sum(accuracies) / len(accuracies)\n",
    "    agg_loss = sum(losses) / len(losses)\n",
    "    return agg_acc, agg_loss\n",
    "\n",
    "def evalulate() : \n",
    "    model.eval()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    for dict_ in tqdm(valid_loader, desc='valid') : \n",
    "        pred = model(dict_['input'].to(device))\n",
    "\n",
    "        loss = criterion(pred, dict_['label'].to(device))\n",
    "        correct = (torch.argmax(pred, dim=1) == dict_['label'].to(device)).sum()\n",
    "        acc = correct.item() / dict_['label'].shape[0]\n",
    "\n",
    "        accuracies.append(acc)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    agg_acc = sum(accuracies) / len(accuracies)\n",
    "    agg_loss = sum(losses) / len(losses)\n",
    "    return agg_acc, agg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-06T15:51:50.857Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1200/1200 [11:40<00:00,  1.71it/s] \n",
      "valid: 100%|██████████| 516/516 [05:10<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                === 1th Epoch ===\n",
      "    \n",
      "        Train Loss : 8.794 | Train Acc : 0.06\n",
      "        Valid Loss : 7.949 | Valid Acc : 0.116\n",
      "        \n",
      "        ============================================\n",
      "        ============================================\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1200/1200 [11:45<00:00,  1.70it/s] \n",
      "valid: 100%|██████████| 516/516 [05:11<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                === 2th Epoch ===\n",
      "    \n",
      "        Train Loss : 7.716 | Train Acc : 0.134\n",
      "        Valid Loss : 7.537 | Valid Acc : 0.156\n",
      "        \n",
      "        ============================================\n",
      "        ============================================\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1200/1200 [11:45<00:00,  1.70it/s]\n",
      "valid: 100%|██████████| 516/516 [05:09<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                === 3th Epoch ===\n",
      "    \n",
      "        Train Loss : 7.368 | Train Acc : 0.164\n",
      "        Valid Loss : 7.199 | Valid Acc : 0.175\n",
      "        \n",
      "        ============================================\n",
      "        ============================================\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  70%|███████   | 841/1200 [08:25<00:45,  7.95it/s] "
     ]
    }
   ],
   "source": [
    "epoches = 20\n",
    "\n",
    "for proc in range(epoches) : \n",
    "    t_acc, t_loss = train()\n",
    "    v_acc, v_loss = evalulate()\n",
    "    print(f\"\"\"\n",
    "                === {proc+1}th Epoch ===\n",
    "    \n",
    "        Train Loss : {round(t_loss, 3)} | Train Acc : {round(t_acc, 3)}\n",
    "        Valid Loss : {round(v_loss, 3)} | Valid Acc : {round(v_acc, 3)}\n",
    "        \n",
    "        ============================================\n",
    "        ============================================\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
